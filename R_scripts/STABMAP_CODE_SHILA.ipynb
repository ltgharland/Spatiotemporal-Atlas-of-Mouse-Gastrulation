{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0a5b84-ff0a-4bb4-995d-8baf42fc22c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shila's Code for StabMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cd4eeda-edd6-4ba4-bf47-173b4aba3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorSubset = function(vec, mat){\n",
    "  # vec is a named vector\n",
    "  # mat is a matrix containing the names or indices for which you want\n",
    "  # to get the entries of vec\n",
    "  \n",
    "  vmat = c(mat)\n",
    "  vvec = vec[vmat]\n",
    "  \n",
    "  vecmat = matrix(vvec, nrow = nrow(mat), ncol = ncol(mat))\n",
    "  colnames(vecmat) <- colnames(mat)\n",
    "  rownames(vecmat) <- rownames(mat)\n",
    "  \n",
    "  return(vecmat)\n",
    "}\n",
    "\n",
    "vectorMatch = function(vec, mat, vecnames){\n",
    "  # vec is an unnamed vector\n",
    "  # vecnames is the names of vec\n",
    "  # mat is a matrix containing the names or indices for which you want\n",
    "  # to get the entries of vec, matching vecnames\n",
    "  \n",
    "  vmat = c(mat)\n",
    "  \n",
    "  vecind = match(vmat,vecnames)\n",
    "  \n",
    "  vvec = vec[vecind]\n",
    "  \n",
    "  vecmat = matrix(vvec, nrow = nrow(mat), ncol = ncol(mat))\n",
    "  colnames(vecmat) <- colnames(mat)\n",
    "  rownames(vecmat) <- rownames(mat)\n",
    "  \n",
    "  return(vecmat)\n",
    "}\n",
    "\n",
    "Harmony_batchFactor = function(embedding,\n",
    "                               batchFactor, ...) {\n",
    "  # batch correct within this embedding, wrapper around Harmony\n",
    "  # batchFactor is a named vector that is matched\n",
    "  # ... passed to HarmonyMatrix\n",
    "  \n",
    "  require(harmony)\n",
    "  \n",
    "  batchFactor_used = batchFactor[rownames(embedding)]\n",
    "  \n",
    "  out = HarmonyMatrix(as.matrix(t(embedding)), batchFactor_used, do_pca = FALSE, ...)\n",
    "  resub_corrected = t(out)\n",
    "  \n",
    "  return(resub_corrected)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a848248b-b2fc-464b-b4fa-8ec59bcbe3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorSubset = function(vec, mat) {\n",
    "  # copied from SpatialUtils to avoid dependency\n",
    "  \n",
    "  # vec is a named vector\n",
    "  # mat is a matrix containing the names or indices for which you want\n",
    "  # to get the entries of vec\n",
    "  \n",
    "  vmat = c(mat)\n",
    "  vvec = vec[vmat]\n",
    "  \n",
    "  vecmat = matrix(vvec, nrow = nrow(mat), ncol = ncol(mat))\n",
    "  colnames(vecmat) <- colnames(mat)\n",
    "  rownames(vecmat) <- rownames(mat)\n",
    "  \n",
    "  return(vecmat)\n",
    "}\n",
    "\n",
    "getArgMin = function(M, return_colnames = TRUE, identicalNA = TRUE) {\n",
    "  # For each row in a matrix calculate the first index\n",
    "  # which gives the minimum value\n",
    "  # keep the rownames\n",
    "  # if return_colnames then extract the column name,\n",
    "  # otherwise just the index\n",
    "  m = max.col(-M, ties.method = \"first\")\n",
    "  \n",
    "  if (return_colnames) {\n",
    "    if (!is.null(colnames(M)[1])) {\n",
    "    m <- colnames(M)[m]\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  names(m) <- rownames(M)\n",
    "  \n",
    "  if (identicalNA) {\n",
    "    # if all the values in a row of M are identical,\n",
    "    # return NA\n",
    "    m[apply(M,1,allEqual)] <- NA\n",
    "  }\n",
    "  \n",
    "  return(m)\n",
    "}\n",
    "\n",
    "getAdaptiveK = function(E,\n",
    "                        labels = NULL,\n",
    "                        local = NULL,\n",
    "                        outputPerCell = TRUE,\n",
    "                        ...) {\n",
    "  \n",
    "  # adaptive k selection for KNN classification\n",
    "  # Given an error matrix E, with rows corresponding to cells\n",
    "  # and columns corresponding to candidate k values, with values\n",
    "  # themselves corresponding to error values (either binary \n",
    "  # for single classification, or continuous after multiple \n",
    "  # classification)\n",
    "  # and given an optional factor labelling/grouping of cells\n",
    "  # identify the k that maximises the accuracy for cells belonging\n",
    "  # to that label/group\n",
    "  # if no labelling given, expect a cell-cell similarity network\n",
    "  # to identify the k that maximises the accuracy for cells within\n",
    "  # that neighbourhood\n",
    "  # if neither are given, simply treat all cells as if they have\n",
    "  # the same labelling/grouping.\n",
    "  \n",
    "  # ... includes return_colnames, whether to give the\n",
    "  # colnames of the best selected, or just the index, \n",
    "  # which is default TRUE\n",
    "  \n",
    "  # if outputPerCell then return a vector of adaptive k\n",
    "  # values for each cell, not just for each label type\n",
    "  # (used for when labels is given)\n",
    "  \n",
    "  # if both labels and local given, labels will be \n",
    "  # prioritised\n",
    "  \n",
    "  # local is a neighbourhood index representation\n",
    "  # as typically output using BiocNeighbors::findKNN()\n",
    "\n",
    "  # example data generation\n",
    "  # data = matrix(rpois(10*20, 10), 10, 20) # 10 genes, 20 cells\n",
    "  # local = BiocNeighbors::findKNN(t(data), k = 5, get.distance = FALSE)$index\n",
    "  # E = matrix(runif(100),20,5)\n",
    "  # colnames(E) <- paste0(\"K_\", 1:5)\n",
    "  # labels = factor(rep(letters[1:2], each = 10))\n",
    "  \n",
    "  require(Matrix)\n",
    "\n",
    "  if (is.null(labels) & is.null(local)) {\n",
    "    labels = factor(rep(\"All\", nrow(E)))\n",
    "  }\n",
    "  \n",
    "  if (!is.null(labels)) {\n",
    "    if (class(labels) != \"factor\") {\n",
    "      labels <- factor(labels)\n",
    "    }\n",
    "    L = fac2sparse(labels)\n",
    "    \n",
    "    LE = L %*% E\n",
    "    \n",
    "    k_best = getArgMin(LE, ...)\n",
    "    \n",
    "    if (outputPerCell) {\n",
    "      k_best <- k_best[labels]\n",
    "      names(k_best) <- rownames(E)\n",
    "    }\n",
    "    \n",
    "    return(k_best) \n",
    "  }\n",
    "\n",
    "  # if function still running, then use the neighbours in local\n",
    "  # ensure that self is also included\n",
    "  # local_self = cbind(seq_len(nrow(E)), local)\n",
    "  local_self = local\n",
    "  \n",
    "  LE = apply(E, 2, function(e) rowSums(vectorSubset(e, local_self)))\n",
    "  \n",
    "  k_best = getArgMin(LE, ...)\n",
    "  names(k_best) <- rownames(E)\n",
    "  \n",
    "  return(k_best)\n",
    "}\n",
    "\n",
    "getModeFirst = function(x, first) {\n",
    "  # identify the mode of x among the first values\n",
    "  # x is a character or a factor\n",
    "  # first is an integer\n",
    "  # x = knn_class[1,]\n",
    "  # first = query_best_k[i]\n",
    "  names(which.max(table(x[1:first])[unique(x[1:first])]))\n",
    "}\n",
    "\n",
    "getQueryK = function(knn, k_local) {\n",
    "  \n",
    "  # knn is a k-nearest neighbour matrix, giving the \n",
    "  # indices of the training set that the query is \n",
    "  # closest to. Rows are the query cells, columns\n",
    "  # are the NNs, should be a large value. Typically\n",
    "  # output using BiocNeighbors::queryKNN(,,k = max(k_local))\n",
    "  \n",
    "  # k_local is an integer vector length of the training\n",
    "  # set, giving the local k to use\n",
    "  # if k_local is given as a single integer, then\n",
    "  # that value is used as k for all observations\n",
    "  \n",
    "  if (length(k_local) == 1) {\n",
    "    k_local <- rep(k_local, nrow(knn))\n",
    "    return(k_local)\n",
    "  }\n",
    "  \n",
    "  # Use 1NN to identify the local best k value\n",
    "  query_best_k = k_local[knn[,1]]\n",
    "  \n",
    "  return(query_best_k)\n",
    "}\n",
    "\n",
    "adaptiveKNN = function(knn,\n",
    "                       class,\n",
    "                       k_local) {\n",
    "  \n",
    "  # knn is a k-nearest neighbour matrix, giving the \n",
    "  # indices of the training set that the query is \n",
    "  # closest to. Rows are the query cells, columns\n",
    "  # are the NNs, should be a large value. Typically\n",
    "  # output using BiocNeighbors::queryKNN(,,k = max(k_local))\n",
    "  \n",
    "  # class is the labels associated with the training\n",
    "  # set\n",
    "  \n",
    "  # k_local is an integer vector length of the training\n",
    "  # set, giving the local k to use\n",
    "  # if k_local is given as a single integer, then\n",
    "  # that value is used as k for all observations\n",
    "  \n",
    "  # example data\n",
    "  # data = matrix(rpois(10*20, 10), 10, 20) # 10 genes, 20 cells\n",
    "  # local = BiocNeighbors::findKNN(t(data), k = 5, get.distance = FALSE)$index\n",
    "  # A = matrix(runif(100),20,5)\n",
    "  # colnames(A) <- paste0(\"K_\", 1:5)\n",
    "  # labels = factor(rep(letters[1:2], each = 10))\n",
    "  # k_local = getAdaptiveK(A, labels = labels)\n",
    "  # data_2 = matrix(rpois(10*30, 10), 10, 30) # 10 genes, 30 cells\n",
    "  # knn = BiocNeighbors::queryKNN(t(data), t(data_2), k = 5, get.distance = FALSE)$index\n",
    "  # class = labels\n",
    "  \n",
    "  # if (length(k_local) == 1) {\n",
    "  #   k_local <- rep(k_local, max(knn))\n",
    "  # }\n",
    "  # \n",
    "  # # first use 1NN to identify the local best k value\n",
    "  # query_best_k = k_local[knn[,1]]\n",
    "  \n",
    "  query_best_k = getQueryK(knn, k_local)\n",
    "  \n",
    "  if (any(query_best_k > ncol(knn))) {\n",
    "    warning(\"k is larger than nearest neighbours provided, taking all neighbours given\")\n",
    "  }\n",
    "  \n",
    "  # convert the KNN names to the class labels\n",
    "  knn_class = vectorSubset(class, knn)\n",
    "  \n",
    "  # extract the most frequent among the nearest local best k neighbours\n",
    "  # new_class = sapply(1:nrow(knn), function(i) getModeFirst(knn_class[i,], query_best_k[i]))\n",
    "  # same as:\n",
    "  new_class = mapply(getModeFirst, split(knn_class, seq_len(nrow(knn_class))), query_best_k,\n",
    "                     USE.NAMES = FALSE)\n",
    "  names(new_class) <- rownames(knn_class)\n",
    "  \n",
    "  return(new_class)\n",
    "}\n",
    "\n",
    "isEqual = function(x,y) {\n",
    "  # returns an integer vector\n",
    "  1*(as.character(x) == as.character(y))\n",
    "}\n",
    "\n",
    "isUnequal = function(x,y) {\n",
    "  # returns an integer vector\n",
    "  1*(as.character(x) != as.character(y))\n",
    "}\n",
    "\n",
    "allEqual = function(x) {\n",
    "  all(x == x[1])\n",
    "}\n",
    "\n",
    "getBinaryError = function(knn,\n",
    "                          k_values,\n",
    "                          class_train,\n",
    "                          class_true) {\n",
    "  \n",
    "  # output is a sparse binary error matrix E\n",
    "  \n",
    "  # knn is a k-nearest neighbour matrix, giving the \n",
    "  # indices of the training set that the query is \n",
    "  # closest to. Rows are the query cells, columns\n",
    "  # are the NNs, should be a large value. Typically\n",
    "  # output using BiocNeighbors::queryKNN(,,k = max(k_values))\n",
    "  \n",
    "  # k_values is an integer vector of the values of k\n",
    "  # to consider for extracting accuracy\n",
    "  # if k_values has names then pass these to \n",
    "  # colnames of E\n",
    "  \n",
    "  # class_train is a factor or character vector of\n",
    "  # classes that corresponds to the indices given\n",
    "  # within knn\n",
    "  \n",
    "  # class_true is a factor or character vector that\n",
    "  # corresponds to the rows of knn\n",
    "  # if class_true has names then pass these to rownames\n",
    "  # of E\n",
    "  \n",
    "  # example data\n",
    "  # data = matrix(rpois(10*20, 10), 10, 20) # 10 genes, 20 cells\n",
    "  # local = BiocNeighbors::findKNN(t(data), k = 5, get.distance = FALSE)$index\n",
    "  # A = matrix(runif(100),20,5)\n",
    "  # colnames(A) <- paste0(\"K_\", 1:5)\n",
    "  # labels = factor(rep(letters[1:2], each = 10))\n",
    "  # k_local = getAdaptiveK(A, labels = labels)\n",
    "  # data_2 = matrix(rpois(10*30, 10), 10, 30) # 10 genes, 30 cells\n",
    "  # knn = BiocNeighbors::queryKNN(t(data), t(data_2), k = 5, get.distance = FALSE)$index\n",
    "  # class = labels\n",
    "  # class_train = labels\n",
    "  # class_true = rep(letters[1], 30)\n",
    "  # k_values = c(1,3,5)\n",
    "  \n",
    "  if (max(unlist(k_values)) > ncol(knn)) {\n",
    "  # if (max(k_values) > ncol(knn)) {\n",
    "    stop(\"largest k value is larger than neighbours provided in knn,\n",
    "         select a smaller k value or provide more neighbours\")\n",
    "  }\n",
    "  \n",
    "  # class_pred = adaptiveKNN(knn, class = class_train, k_local = k_values[1])\n",
    "  # isEqual(class_pred, class_true)\n",
    "  \n",
    "  class_pred = mapply(adaptiveKNN, k_values, MoreArgs = list(class = class_train, knn = knn))\n",
    "  E = as(apply(class_pred, 2, isUnequal, y = class_true), \"sparseMatrix\")\n",
    "  \n",
    "  rownames(E) <- names(class_true)\n",
    "  colnames(E) <- names(k_values)\n",
    "  \n",
    "  return(E)\n",
    "}\n",
    "\n",
    "combineBinaryErrors = function(E_list) {\n",
    "  # E_list is a list containing matrices\n",
    "  # each matrix must have the same number of columns (k-values)\n",
    "  # and contain rownames (cells)\n",
    "  \n",
    "  # example data\n",
    "  # E_1 = as(matrix(rbinom(50, 1, 0.5), 10, 5), \"sparseMatrix\")\n",
    "  # rownames(E_1) <- letters[1:10]\n",
    "  # E_2 = as(matrix(rbinom(60, 1, 0.5), 12, 5), \"sparseMatrix\")\n",
    "  # rownames(E_2) <- letters[5:16]\n",
    "  # E_list = list(E_1, E_2)\n",
    "\n",
    "  if (!allEqual(unlist(lapply(E_list, ncol)))) {\n",
    "    stop(\"each matrix in E_list must have the same number of columns\")\n",
    "  }\n",
    "  \n",
    "  if (any(unlist(lapply(E_list, function(x) is.null(rownames(x)))))) {\n",
    "    stop(\"each matrix in E_list must have associated rownames\")\n",
    "  }\n",
    "  \n",
    "  all_rows = unlist(lapply(E_list, rownames))\n",
    "  \n",
    "  E_exp = do.call(rbind, E_list)\n",
    "  E_split = split.data.frame(E_exp, all_rows)\n",
    "  \n",
    "  # data becomes dense at this stage\n",
    "  E_means = lapply(E_split, colMeans, na.rm = TRUE)\n",
    "  \n",
    "  E = as(do.call(rbind, E_means), \"sparseMatrix\")\n",
    "  \n",
    "  return(E)  \n",
    "}\n",
    "\n",
    "\n",
    "getDensityK = function(coords, k_values = k_values, dist_maxK = 100) {\n",
    "  \n",
    "  # coords is a cells (rows) x dimensions matrix for which distances should be calculated\n",
    "  # k_values is a numeric character of maximum k-values to use\n",
    "  # dist_maxK is the maximum distance to consider for estimating the local density\n",
    "  \n",
    "  # the output is a list of k-values based on the density for the possible values\n",
    "  \n",
    "  require(BiocNeighbors)\n",
    "  \n",
    "  dists = findKNN(coords, k = dist_maxK, get.distance = TRUE)$distance[,dist_maxK]\n",
    "  \n",
    "  k_norm_unscaled = (1/dists) / max(1/dists)\n",
    "  \n",
    "  k_norm = ceiling(outer(k_norm_unscaled, k_values))\n",
    "  rownames(k_norm) <- rownames(coords)\n",
    "  \n",
    "  # k_norm_split = split.data.frame(t(k_norm), 1:ncol(k_norm))\n",
    "  k_norm_split = sapply(seq_len(ncol(k_norm)), function(i) k_norm[,i], simplify = FALSE)\n",
    "  \n",
    "  return(k_norm_split)\n",
    "}\n",
    "\n",
    "getBestColumn = function(E,\n",
    "                         balanced_labels = NULL) {\n",
    "  # returns the index of the best performing column of E\n",
    "  # if balanced_labels given then return the best\n",
    "  # given the balanced accuracy, otherwise just total accuracy\n",
    "  \n",
    "  if (is.null(balanced_labels)) {\n",
    "    return(which.min(colMeans(E, na.rm = TRUE)))\n",
    "  } else {\n",
    "    E_lab = apply(E, 2, function(x) tapply(x, balanced_labels, mean))\n",
    "    return(which.min(colMeans(E_lab, na.rm = TRUE))) \n",
    "  }\n",
    "}\n",
    "\n",
    "# core functions from Jonny 2019 paper\n",
    "getHVGs = function(sce, min.mean = 1e-3){\n",
    "  # require(biomaRt)\n",
    "  decomp = modelGeneVar(assay(sce, \"logcounts\"), block = sce$sample, span = 0.05)\n",
    "  decomp = decomp[decomp$mean > min.mean,]\n",
    "  \n",
    "  #exclude sex genes\n",
    "  xist = \"ENSMUSG00000086503\"\n",
    "  # mouse_ensembl = useMart(\"ensembl\")\n",
    "  # mouse_ensembl = useDataset(\"mmusculus_gene_ensembl\", mart = mouse_ensembl)\n",
    "  # gene_map = getBM(attributes=c(\"ensembl_gene_id\", \"chromosome_name\"), filters = \"ensembl_gene_id\", values = rownames(decomp), mart = mouse_ensembl)\n",
    "  # ychr = gene_map[gene_map[,2] == \"Y\", 1]\n",
    "  ychr = read.table(\"/Users/ghazan01/Dropbox/Backup/fromjonny/misc/ygenes.tab\", stringsAsFactors = FALSE)[,1]\n",
    "  other = c(\"tomato-td\") #for the chimera\n",
    "  decomp = decomp[!rownames(decomp) %in% c(xist, ychr, other),]\n",
    "  \n",
    "  decomp$FDR = p.adjust(decomp$p.value, method = \"fdr\")\n",
    "  return(rownames(decomp)[decomp$p.value < 0.05])\n",
    "}\n",
    "\n",
    "getMergeOrder = function(s, meta) {\n",
    "  require(gtools)\n",
    "  s_uniq = as.character(unique(s))\n",
    "  rownames(meta) <- as.character(meta$sample)\n",
    "  s_split = split(s_uniq, meta[as.character(s_uniq), \"stage\"])\n",
    "  s_split <- s_split[rev(mixedsort(names(s_split)))]\n",
    "  s_split_ordered = lapply(s_split, function(ss){\n",
    "    ss[order(meta[as.character(ss), \"ncells\"], decreasing = TRUE)]\n",
    "  })\n",
    "  return(s_split_ordered)\n",
    "}\n",
    "\n",
    "doBatchCorrect = function(sce) {\n",
    "  \n",
    "  # perform the integration once outside of the loop, then call within\n",
    "  sce <- multiBatchNorm(sce, batch = sce$sample)\n",
    "  # fit_train_test = modelGeneVar(assay(sce_train_test, \"logcounts\"), block = sce_train_test$sample)\n",
    "  # HVG_train_test = getTopHVGs(fit_train_test, fdr.threshold = 0.05)\n",
    "  HVG = getHVGs(sce)\n",
    "  mergeOrder = getMergeOrder(sce$sample, mt)\n",
    "  pc_out = fastMNN(sce, batch = sce$sample,\n",
    "                   subset.row = HVG,\n",
    "                   merge.order = mergeOrder\n",
    "  )\n",
    "  \n",
    "  pc = reducedDim(pc_out, \"corrected\")\n",
    "  \n",
    "  umap = uwot::umap(pc)\n",
    "  plot(umap)\n",
    "  \n",
    "  return(pc)\n",
    "}\n",
    "\n",
    "\n",
    "smoothLocal = function(best_k, local, smooth = 10, mean_type = \"geometric\") {\n",
    "  # best_k is a named vector of local best k values\n",
    "  # local is a matrix with rows same as best_k and values indices of best_k\n",
    "  nms = names(best_k)\n",
    "  \n",
    "  if (mean_type == \"arithmetic\") {\n",
    "  best_k_smooth = ceiling(rowMeans(vectorSubset(best_k, local[,1:smooth])))\n",
    "  }\n",
    "  if (mean_type == \"geometric\") {\n",
    "    best_k_smooth = ceiling(apply(vectorSubset(best_k, local[,1:smooth]),1, gm_mean))\n",
    "  }\n",
    "  names(best_k_smooth) <- nms\n",
    "  return(best_k_smooth)\n",
    "}\n",
    "\n",
    "gm_mean = function(x, na.rm=TRUE){\n",
    "  if (all(is.na(x))) return(NA)\n",
    "  exp(sum(log(x[x > 0]), na.rm=na.rm) / sum(!is.na(x)))\n",
    "}\n",
    "\n",
    "queryNamedKNN = function(coords_reference, coords_query, k) {\n",
    "  \n",
    "  require(BiocNeighbors)\n",
    "  \n",
    "  knn = queryKNN(\n",
    "    coords_reference,\n",
    "    coords_query,\n",
    "    k = k, get.distance = FALSE)$index\n",
    "  rownames(knn) <- rownames(coords_query)\n",
    "  knn_name = vectorSubset(rownames(coords_reference), knn)\n",
    "  \n",
    "  return(knn_name)\n",
    "}\n",
    "\n",
    "buildLabelsDataFrame = function(labels, resubstituted_labels, k_adaptive) {\n",
    "  # labels is a named character vector with true labels\n",
    "  # resubstituted_labels is a named character vector with\n",
    "  # extra labels\n",
    "  # k_adaptive is a named vector of the k-values, this could \n",
    "  # be a single integer when fixed\n",
    "  \n",
    "  # output a dataframe with rows the same as resubstituted_labels\n",
    "  # and columns for input_labels, predicted_labels, and resubstituted_labels\n",
    "  \n",
    "  df = data.frame(input_labels = labels[names(resubstituted_labels)],\n",
    "                  resubstituted_labels = resubstituted_labels,\n",
    "                  predicted_labels = resubstituted_labels,\n",
    "                  row.names = names(resubstituted_labels))\n",
    "  df[names(labels), \"predicted_labels\"] <- labels\n",
    "  \n",
    "  if (length(k_adaptive) == 1) {\n",
    "    df$k = k_adaptive\n",
    "  } else {\n",
    "    df$k <- k_adaptive[rownames(df)]\n",
    "  }\n",
    "  \n",
    "  return(df)\n",
    "}\n",
    "\n",
    "getBinaryErrorFromPredictions = function(pred, labels) {\n",
    "  # pred is a matrix of class label predictions\n",
    "  # with named rows\n",
    "  # labels is a named vector of true labels\n",
    "  \n",
    "  # output is a binary error matrix, sparse\n",
    "  \n",
    "  E = as(apply(pred, 2, isUnequal, y = labels[rownames(pred)]), \"sparseMatrix\")\n",
    "  rownames(E) <- names(labels)\n",
    "  colnames(E) <- colnames(pred)\n",
    "  \n",
    "  return(E)\n",
    "}\n",
    "\n",
    "embeddingKNN = function(\n",
    "  coords,\n",
    "  labels,\n",
    "  type = \"adaptive_local\",\n",
    "  k_values = 1:50,\n",
    "  error_measure = \"simple_error\",\n",
    "  adaptive_nFold = 2,\n",
    "  adaptive_nRep = 5,\n",
    "  adaptive_local_nhood = 100,\n",
    "  adaptive_local_smooth = 10,\n",
    "  adaptive_density_maxK = 100,\n",
    "  verbose = TRUE\n",
    ") {\n",
    "  \n",
    "  # to-do: \n",
    "  # the cross validation step can be parallelised\n",
    "  # provide a priori values for adaptive k rather than need to calculate\n",
    "  \n",
    "  # coords is cells (rows) x dimensions data matrix, on which euclidean \n",
    "  # distances are to be calculated. coords must have rownames\n",
    "  # labels is a named character vector\n",
    "  # type is one of \"adaptive_local\", \"adaptive_labels\", \n",
    "  # \"uniform_optimised\", \"uniform_fixed\", or \"adaptive_density\"\n",
    "  # k_values is a numeric vector of potential values. if type is \"uniform_fixed\",\n",
    "  # then the first value of k_values is used.\n",
    "  # error_measure is the error type to use for selection. Simple error is used\n",
    "  # for adaptive_local and adaptive_labels (since balanced error can be noisy)\n",
    "  # adaptive_nFold is the number of folds for adaptive selection cross-validation\n",
    "  # adaptive_nRep is the number of repetitions of adaptive selection cross-validation\n",
    "  # adaptive_local_nhood is the neighbourhood size for optimising locally\n",
    "  # adaptive_local_smooth is the number of neighbours to use for smoothing locally\n",
    "  # adaptive_density_maxK is the maximum k to use for estimating the relative density\n",
    "  \n",
    "  # output is a dataframe with rows the same as coords, and same rownames\n",
    "  # columns are input_labels: NA-filled labels that were input\n",
    "  # resubstituted_labels is full reclassified labels including for the training data\n",
    "  # predicted_labels = input_labels is the classified labels along with the input\n",
    "  # training labels\n",
    "  \n",
    "  # example data\n",
    "  # coords = matrix(rnorm(1000), 100, 10)\n",
    "  # rownames(coords) <- paste0(\"cell_\", 1:nrow(coords))\n",
    "  # labels = rep(paste0(\"type_\", letters[1:5]), 10)\n",
    "  # names(labels) <- rownames(coords)[1:length(labels)]\n",
    "  \n",
    "  require(BiocNeighbors)\n",
    "  require(Matrix)\n",
    "\n",
    "  if (is.null(rownames(coords)[1])) {\n",
    "    stop(\"coords must have rownames\")\n",
    "  }\n",
    "  \n",
    "  if (is.null(names(labels)[1])) {\n",
    "    stop(\"labels must have names\")\n",
    "  }\n",
    "  \n",
    "  max_k = max(k_values)\n",
    "  \n",
    "  coords_train = coords[names(labels),]\n",
    "  \n",
    "  if (type == \"uniform_fixed\") {\n",
    "    k = k_values[1]\n",
    "    \n",
    "    knn = queryNamedKNN(coords_train, coords, k = k)\n",
    "    \n",
    "    resubstituted_labels = adaptiveKNN(knn,\n",
    "                                       labels,\n",
    "                                       k)\n",
    "    \n",
    "    out = buildLabelsDataFrame(labels, resubstituted_labels, k_adaptive = k)\n",
    "    \n",
    "    return(out)\n",
    "  }\n",
    "  \n",
    "  # all other types require some adaptive or optimised component\n",
    "  \n",
    "  # if type is based on density (of all data), then calculate the error rates\n",
    "  # for these density based choices, and select the best k's for them\n",
    "  \n",
    "  if (type == \"adaptive_density\") {\n",
    "    \n",
    "    densityK_all = getDensityK(coords, k_values = k_values, dist_maxK = adaptive_density_maxK)\n",
    "    \n",
    "    max_k = max(unlist(densityK_all), na.rm = TRUE)\n",
    "    \n",
    "    knn = queryNamedKNN(coords_train, coords_train, k = max_k)\n",
    "    \n",
    "    densityK_pred = mapply(adaptiveKNN, densityK_all, MoreArgs = list(class = labels, knn = knn))\n",
    "    \n",
    "    E = getBinaryErrorFromPredictions(densityK_pred, labels)\n",
    "    \n",
    "    # select the best column based on the error type\n",
    "    if (error_measure == \"simple_error\") {\n",
    "      best_column = getBestColumn(E)\n",
    "    }\n",
    "    if (error_measure == \"balanced_error\") {\n",
    "      best_column = getBestColumn(E, balanced_labels = labels[rownames(E)])\n",
    "    }\n",
    "    k_adaptive = densityK_all[[best_column]]\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # if neither of above types are chosen, then an error matrix\n",
    "  # is needed, using internal cross-validation\n",
    "  \n",
    "  E_list = list()\n",
    "  \n",
    "  for (Rep in seq_len(adaptive_nRep)) {\n",
    "    \n",
    "    train_k = sample(seq_len(adaptive_nFold), nrow(coords_train),\n",
    "                     prob = rep(1,adaptive_nFold), replace = TRUE)\n",
    "    \n",
    "    if (verbose) print(paste(\"Rep\", Rep, \"of\", adaptive_nRep))\n",
    "    \n",
    "    for (fold in seq_len(adaptive_nFold)) {\n",
    "      \n",
    "      if (verbose) print(paste(\"Fold\", fold, \"of\", adaptive_nFold))\n",
    "      \n",
    "      coords_train_k = coords_train[train_k == fold,]\n",
    "      coords_test_k = coords_train[!train_k == fold,]\n",
    "      \n",
    "      knn = queryNamedKNN(coords_train_k, coords_test_k, k = max_k)\n",
    "      \n",
    "      labels_train = labels[rownames(coords_train_k)]\n",
    "      labels_test = labels[rownames(coords_test_k)]\n",
    "      \n",
    "      E = getBinaryError(knn = knn,\n",
    "                         k_values = k_values,\n",
    "                         class_train = labels_train,\n",
    "                         class_true = labels_test)\n",
    "      \n",
    "      E_list[[length(E_list) + 1]] <- E\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }\n",
    "  E = combineBinaryErrors(E_list)[rownames(coords_train),]\n",
    "  \n",
    "  \n",
    "  if (type == \"uniform_optimised\") {\n",
    "    \n",
    "    # select the best column based on the error type\n",
    "    if (error_measure == \"simple_error\") {\n",
    "      best_column = getBestColumn(E)\n",
    "    }\n",
    "    if (error_measure == \"balanced_error\") {\n",
    "      best_column = getBestColumn(E, balanced_labels = labels[rownames(E)])\n",
    "    }\n",
    "    k_adaptive = k_values[best_column]\n",
    "  }\n",
    "  \n",
    "  if (type == \"adaptive_labels\") {\n",
    "    best_k_labels_index = getAdaptiveK(E,\n",
    "                                       labels = labels[rownames(E)],\n",
    "                                       local = NULL,\n",
    "                                       outputPerCell = TRUE)\n",
    "    best_k_labels <- vectorSubset(k_values, as.matrix(best_k_labels_index))[,1]\n",
    "    \n",
    "    # if any are NA, select the geometric mean value among the rest\n",
    "    best_k_labels[is.na(best_k_labels)] <- ceiling(gm_mean(best_k_labels))\n",
    "    \n",
    "    k_adaptive = best_k_labels[names(labels)]\n",
    "  }\n",
    "  \n",
    "  if (type == \"adaptive_local\") {\n",
    "    \n",
    "    local = queryNamedKNN(coords_train, coords_train, k = adaptive_local_nhood)\n",
    "    \n",
    "    best_k_local_index = getAdaptiveK(E,\n",
    "                                      local = local,\n",
    "                                      outputPerCell = TRUE)\n",
    "    best_k_local_unsmoothed <- vectorSubset(k_values, as.matrix(best_k_local_index))[,1]\n",
    "    \n",
    "    if (any(is.na(best_k_local_unsmoothed))) {\n",
    "      defined = names(best_k_local_unsmoothed)[!is.na(best_k_local_unsmoothed)]\n",
    "      \n",
    "      local_defined = queryNamedKNN(coords_train[defined,], coords_train, k = adaptive_local_nhood)\n",
    "    } else {\n",
    "      local_defined = local\n",
    "    }\n",
    "    \n",
    "    best_k_local <- smoothLocal(best_k_local_unsmoothed, local_defined, smooth = adaptive_local_smooth)\n",
    "    \n",
    "    k_adaptive = best_k_local[names(labels)]\n",
    "  }\n",
    "  \n",
    "  # with k_adaptive defined, perform the classification and extract out\n",
    "  \n",
    "  max_k = max(k_adaptive)\n",
    "  \n",
    "  knn = queryNamedKNN(coords_train, coords, k = max_k)\n",
    "  \n",
    "  resubstituted_labels = adaptiveKNN(knn,\n",
    "                                     labels,\n",
    "                                     k_adaptive)\n",
    "  \n",
    "  out = buildLabelsDataFrame(labels, resubstituted_labels, k_adaptive = k_adaptive)\n",
    "  \n",
    "  return(out)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec3be824-0b75-4b50-9bf2-4f120284bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducedMNN_batchFactor = function(embedding,\n",
    "                                  batchFactor,\n",
    "                                  ...) {\n",
    "  # batch correct within this embedding, wrapper around reducedMNN\n",
    "  # batchFactor is a named vector that is matched\n",
    "  # ... passed to reducedMNN\n",
    "  \n",
    "  require(batchelor)\n",
    "  \n",
    "  # for some reason reducedMNN only takes dense matrices\n",
    "  embedding <- as.matrix(embedding)\n",
    "  \n",
    "  batchFactor_used = batchFactor[rownames(embedding)]\n",
    "  \n",
    "  out = reducedMNN(embedding, batch = batchFactor_used, ...)\n",
    "  resub_corrected = out$corrected\n",
    "  \n",
    "  return(resub_corrected)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
